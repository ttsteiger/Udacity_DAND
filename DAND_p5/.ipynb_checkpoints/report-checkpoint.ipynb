{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {margin-left: 0 !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Persons of Interest in the Enron Corpus Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "## Data Exploration\n",
    "\n",
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_dict_to_df(dictionary, features, remove_NaN=True, \n",
    "                        remove_all_zeroes=True, remove_any_zeroes=False, \n",
    "                        sort_keys=False):\n",
    "    \"\"\"\n",
    "    Convert dictionary to a pandas data frame of features.\n",
    "    \n",
    "    Args:\n",
    "        dictionary: Dictionary containing the feature names as keys and the \n",
    "            corresponding values.\n",
    "        features: List of feature names. First feature passed needs to be 'poi'.\n",
    "        remove_NaN: True converts all \"NaN\" strings to 0.\n",
    "        remove_all_zeroes: True omits all 0 data points.\n",
    "        remove_any_zeroes: True omits single 0 data points.\n",
    "        sort_keys: True sorts the dictionary keys in alphabetical order before\n",
    "            adding the data points to the data frame.\n",
    "\n",
    "    Returns:\n",
    "        Function returns a pandas data frame with each row representing a data \n",
    "        point with the specified features in its columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # check that first feature passed is 'poi'\n",
    "    assert (features[0] == 'poi'), \"The first feature needs to be 'poi'!\"\n",
    "\n",
    "    # data frame to store the data points as individual rows\n",
    "    df = pd.DataFrame(columns=['name'] + features)\n",
    "\n",
    "    # sort keys alphabetically if sort_keys is set to True\n",
    "    if sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    # loop trough the data dictionary \n",
    "    for key in keys:\n",
    "        \n",
    "        val_dict = {'name': key} # first entry of data point is the name of the person\n",
    "\n",
    "        for feature in features:\n",
    "            # check if specified feature exists, throw a warning if not and \n",
    "            # stop the function\n",
    "            try:\n",
    "                val = dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print(\"error: key \", feature, \" not present\")\n",
    "                return\n",
    "\n",
    "            val = dictionary[key][feature]\n",
    "\n",
    "            # set 'NaN' strings to np.NaN values\n",
    "            if val == \"NaN\" and not remove_NaN:\n",
    "                val = np.NaN\n",
    "            # set NaN values to 0 if remove_NaN is set to True\n",
    "            elif val == \"NaN\" and remove_NaN:\n",
    "                val = 0\n",
    "\n",
    "            val_dict[feature] = val\n",
    "\n",
    "        # do not add all zero data points if remove_all_zeroes is set to True\n",
    "        if remove_all_zeroes:       \n",
    "            append = False\n",
    "            for key, val in val_dict.items(): \n",
    "                if key != 'poi' and key != 'name': # exclude 'poi' and 'name' from criteria\n",
    "                    if val != 0 and val != \"NaN\":\n",
    "                        append = True\n",
    "                        break\n",
    "        \n",
    "        # don not add single zero data points if remove_any_zeroes is set to \n",
    "        # True\n",
    "        elif remove_any_zeroes:\n",
    "            append = True\n",
    "            keys =  [f for f in features if f not in ('poi', 'name')] # exclude 'poi' and 'name' from criteria\n",
    "            val_list = [val_dict.get(k) for k in keys] # list containing values of remaining features\n",
    "\n",
    "            if 0 in val_list or \"NaN\" in val_list:\n",
    "                append = False\n",
    "        \n",
    "        # all data points are added \n",
    "        else:\n",
    "            append = True\n",
    "    \n",
    "        \n",
    "        # append data point if it is flagged for addition\n",
    "        if append:\n",
    "            df = df.append(val_dict, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 22)\n"
     ]
    }
   ],
   "source": [
    "# load dictionary containing the dataset\n",
    "with open(\"enron_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# feature list\n",
    "features = ['poi', 'bonus', 'deferral_payments', 'deferred_income', \n",
    "            'director_fees', 'exercised_stock_options', 'expenses', \n",
    "            'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', \n",
    "            'restricted_stock_deferred', 'salary', 'total_payments', \n",
    "            'total_stock_value', 'email_address', 'from_messages', \n",
    "            'from_poi_to_this_person', 'from_this_person_to_poi', \n",
    "            'shared_receipt_with_poi', 'to_messages']\n",
    "\n",
    "# convert specified features to data frame\n",
    "data_df = convert_dict_to_df(data_dict, features, remove_NaN=False, \n",
    "                        remove_all_zeroes=True, remove_any_zeroes=False, \n",
    "                        sort_keys=True)\n",
    "\n",
    "print(data_df.shape)\n",
    "#print(data_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['poi'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying dataset for this project is a combination of Enron email and financial data. The data is present in the `enron_dataset.pkl` file where it is stored in a dictionary structure. Each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. \n",
    "\n",
    "The data contains three major feature categories: POI labels, financial features and email features. The 21 feature names and their type are described in the table below.\n",
    "\n",
    "| Feature                   | Type        |\n",
    "|-------------------------- | ----------- |\n",
    "| poi                       | categorical |\n",
    "| bonus                     | numerical   |\n",
    "| deferral_payments         | numerical   |\n",
    "| deferred_income           | numerical   |\n",
    "| director_fees             | numerical   |\n",
    "| exercised_stock_options   | numerical   |\n",
    "| expenses                  | numerical   |\n",
    "| loan_advances             | numerical   |\n",
    "| long_term_incentive       | numerical   |\n",
    "| other                     | numerical   |\n",
    "| restricted_stock          | numerical   |\n",
    "| restricted_stock_deferred | numerical   |\n",
    "| salary                    | numerical   |\n",
    "| total_payments            | numerical   |\n",
    "| total_stock_value         | numerical   |\n",
    "| email_address             | text        |\n",
    "| from_messages             | numerical   |\n",
    "| from_poi_to_this_person   | numerical   |\n",
    "| from_this_person_to_poi   | numerical   |\n",
    "| shared_receipt_with_poi   | numerical   |\n",
    "| to_messages               | numerical   |\n",
    "\n",
    "The dataset contains information about 146 different data points. Of those, 18 are marked as POI while 128 are not.\n",
    "\n",
    "Missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                           0\n",
      "poi                            0\n",
      "bonus                         64\n",
      "deferral_payments            107\n",
      "deferred_income               97\n",
      "director_fees                129\n",
      "exercised_stock_options       44\n",
      "expenses                      51\n",
      "loan_advances                142\n",
      "long_term_incentive           80\n",
      "other                         53\n",
      "restricted_stock              36\n",
      "restricted_stock_deferred    128\n",
      "salary                        51\n",
      "total_payments                21\n",
      "total_stock_value             20\n",
      "email_address                 35\n",
      "from_messages                 60\n",
      "from_poi_to_this_person       60\n",
      "from_this_person_to_poi       60\n",
      "shared_receipt_with_poi       60\n",
      "to_messages                   60\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count number of NaN values in each column\n",
    "print(data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a lot of features with missing values. One can see that it is based on the finacial data and that only for 86 point a connection to the email dataset could be made (60 data points without email data). For the features 'defferal_payments', 'director_fees', 'loan_advances' and 'restricted_stock_deferred' only few data is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "In the financial data a strange outlier was found. This data point had the largest values for all the different financial feature and was identified as the total column from the spreadsheet. This line was dropped and not considered further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop 'TOTAL' row\n",
    "data_df = data_df[data_df['name'] != 'TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "\n",
    "from_poi_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>from_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BELDEN TIMOTHY N</td>\n",
       "      <td>484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOWEN JR RAYMOND M</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CALGER CHRISTOPHER F</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CAUSEY RICHARD A</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>COLWELL WESLEY</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DELAINEY DAVID W</td>\n",
       "      <td>3069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FASTOW ANDREW S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GLISAN JR BEN F</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>HANNON KEVIN P</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>HIRKO JOSEPH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>KOENIG MARK E</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>KOPPER MICHAEL J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LAY KENNETH L</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>RICE KENNETH D</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>RIEKER PAULA H</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>SHELBY REX</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SKILLING JEFFREY K</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>YEAGER F SCOTT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  from_messages\n",
       "7        BELDEN TIMOTHY N          484.0\n",
       "15     BOWEN JR RAYMOND M           27.0\n",
       "20   CALGER CHRISTOPHER F          144.0\n",
       "22       CAUSEY RICHARD A           49.0\n",
       "26         COLWELL WESLEY           40.0\n",
       "31       DELAINEY DAVID W         3069.0\n",
       "43        FASTOW ANDREW S            NaN\n",
       "54        GLISAN JR BEN F           16.0\n",
       "59         HANNON KEVIN P           32.0\n",
       "65           HIRKO JOSEPH            NaN\n",
       "76          KOENIG MARK E           61.0\n",
       "77       KOPPER MICHAEL J            NaN\n",
       "79          LAY KENNETH L           36.0\n",
       "112        RICE KENNETH D           18.0\n",
       "113        RIEKER PAULA H           82.0\n",
       "119            SHELBY REX           39.0\n",
       "122    SKILLING JEFFREY K          108.0\n",
       "144        YEAGER F SCOTT            NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_email_from_filename(filename, start, end):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    email_address = \"\"\n",
    "    \n",
    "    m = re.search(\"{}(.*){}\".format(start, end), filename)\n",
    "    if m:\n",
    "        email_address = m.group(1)\n",
    "    \n",
    "    return email_address\n",
    "\n",
    "def get_sender_from_fileline(line):\n",
    "    \"\"\"\n",
    "    enron_mail_20110402/maildir/allen-p/deleted_items/127.\n",
    "    \"\"\"\n",
    "    start = \"enron_mail_20110402\\/maildir\\/\"\n",
    "    end = \"\\/.*\"\n",
    "    m = re.search(\"{}(.*){}\".format(start, end), line)\n",
    "    sender = m.group(1)\n",
    "    \n",
    "    return sender\n",
    "\n",
    "data_df[(data_df['poi'] == True)][['name', 'from_messages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = \"./emails_by_address/\"\n",
    "poi_list = [\"delaney-d\", \"skilling-j\"]\n",
    "\n",
    "\n",
    "from_poi_deleted_dict = {}\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    # only check files with emails to that address\n",
    "    if filename.startswith(\"to_\"):\n",
    "        # extract email from filename   \n",
    "        email = get_email_from_filename(filename, \"to\\_\", \"\\.txt\")\n",
    "        \n",
    "        from_poi_deleted_dict[email] = 0\n",
    "        \n",
    "        with open(os.path.join(dir_path, filename), 'r') as f:\n",
    "            for line in f:\n",
    "                sender = get_sender_from_fileline(line)\n",
    "                #print(sender)\n",
    "                \"\"\"\n",
    "                print(sender)\n",
    "                folder = get_folder_from_fileline(line)\n",
    "                \n",
    "                if sender in poi_list and folder == \"deleted_items\":\n",
    "                    from_poi_deleted_dict[email] += 1\n",
    "\n",
    "\"\"\"\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>poi</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>...</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FASTOW ANDREW S</td>\n",
       "      <td>True</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1736055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440698.0</td>\n",
       "      <td>2424083.0</td>\n",
       "      <td>1794412.0</td>\n",
       "      <td>andrew.fastow@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name   poi      bonus  deferral_payments  deferred_income  \\\n",
       "43  FASTOW ANDREW S  True  1300000.0                NaN       -1386055.0   \n",
       "\n",
       "   director_fees  exercised_stock_options  expenses loan_advances  \\\n",
       "43           NaN                      NaN   55921.0           NaN   \n",
       "\n",
       "    long_term_incentive     ...       restricted_stock_deferred    salary  \\\n",
       "43            1736055.0     ...                             NaN  440698.0   \n",
       "\n",
       "    total_payments  total_stock_value            email_address  from_messages  \\\n",
       "43       2424083.0          1794412.0  andrew.fastow@enron.com            NaN   \n",
       "\n",
       "   from_poi_to_this_person  from_this_person_to_poi  shared_receipt_with_poi  \\\n",
       "43                     NaN                      NaN                      NaN   \n",
       "\n",
       "    to_messages  \n",
       "43          NaN  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['email_address'] == 'andrew.fastow@enron.com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
